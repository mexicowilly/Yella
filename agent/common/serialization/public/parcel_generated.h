// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_PARCEL_YELLA_FB_H_
#define FLATBUFFERS_GENERATED_PARCEL_YELLA_FB_H_

#include "flatbuffers/flatbuffers.h"

namespace yella {
namespace fb {

struct sequence;

struct group;

struct parcel;

enum compression {
  compression_NONE = 0,
  compression_LZ4 = 1,
  compression_MIN = compression_NONE,
  compression_MAX = compression_LZ4
};

inline const compression (&EnumValuescompression())[2] {
  static const compression values[] = {
    compression_NONE,
    compression_LZ4
  };
  return values;
}

inline const char * const *EnumNamescompression() {
  static const char * const names[] = {
    "NONE",
    "LZ4",
    nullptr
  };
  return names;
}

inline const char *EnumNamecompression(compression e) {
  if (e < compression_NONE || e > compression_LZ4) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamescompression()[index];
}

enum group_disposition {
  group_disposition_MORE = 0,
  group_disposition_END = 1,
  group_disposition_MIN = group_disposition_MORE,
  group_disposition_MAX = group_disposition_END
};

inline const group_disposition (&EnumValuesgroup_disposition())[2] {
  static const group_disposition values[] = {
    group_disposition_MORE,
    group_disposition_END
  };
  return values;
}

inline const char * const *EnumNamesgroup_disposition() {
  static const char * const names[] = {
    "MORE",
    "END",
    nullptr
  };
  return names;
}

inline const char *EnumNamegroup_disposition(group_disposition e) {
  if (e < group_disposition_MORE || e > group_disposition_END) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesgroup_disposition()[index];
}

struct sequence FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_MAJOR = 4,
    VT_MINOR = 6
  };
  uint32_t major() const {
    return GetField<uint32_t>(VT_MAJOR, 0);
  }
  uint32_t minor() const {
    return GetField<uint32_t>(VT_MINOR, 0);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint32_t>(verifier, VT_MAJOR) &&
           VerifyField<uint32_t>(verifier, VT_MINOR) &&
           verifier.EndTable();
  }
};

struct sequenceBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_major(uint32_t major) {
    fbb_.AddElement<uint32_t>(sequence::VT_MAJOR, major, 0);
  }
  void add_minor(uint32_t minor) {
    fbb_.AddElement<uint32_t>(sequence::VT_MINOR, minor, 0);
  }
  explicit sequenceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  sequenceBuilder &operator=(const sequenceBuilder &);
  flatbuffers::Offset<sequence> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<sequence>(end);
    return o;
  }
};

inline flatbuffers::Offset<sequence> Createsequence(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint32_t major = 0,
    uint32_t minor = 0) {
  sequenceBuilder builder_(_fbb);
  builder_.add_minor(minor);
  builder_.add_major(major);
  return builder_.Finish();
}

struct group FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ID = 4,
    VT_DISPOSITION = 6
  };
  const flatbuffers::String *id() const {
    return GetPointer<const flatbuffers::String *>(VT_ID);
  }
  group_disposition disposition() const {
    return static_cast<group_disposition>(GetField<int8_t>(VT_DISPOSITION, 0));
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_ID) &&
           verifier.VerifyString(id()) &&
           VerifyField<int8_t>(verifier, VT_DISPOSITION) &&
           verifier.EndTable();
  }
};

struct groupBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_id(flatbuffers::Offset<flatbuffers::String> id) {
    fbb_.AddOffset(group::VT_ID, id);
  }
  void add_disposition(group_disposition disposition) {
    fbb_.AddElement<int8_t>(group::VT_DISPOSITION, static_cast<int8_t>(disposition), 0);
  }
  explicit groupBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  groupBuilder &operator=(const groupBuilder &);
  flatbuffers::Offset<group> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<group>(end);
    return o;
  }
};

inline flatbuffers::Offset<group> Creategroup(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> id = 0,
    group_disposition disposition = group_disposition_MORE) {
  groupBuilder builder_(_fbb);
  builder_.add_id(id);
  builder_.add_disposition(disposition);
  return builder_.Finish();
}

inline flatbuffers::Offset<group> CreategroupDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *id = nullptr,
    group_disposition disposition = group_disposition_MORE) {
  auto id__ = id ? _fbb.CreateString(id) : 0;
  return yella::fb::Creategroup(
      _fbb,
      id__,
      disposition);
}

struct parcel FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_SECONDS_SINCE_EPOCH = 4,
    VT_SENDER = 6,
    VT_RECIPIENT = 8,
    VT_TYPE = 10,
    VT_CMP = 12,
    VT_SEQ = 14,
    VT_GRP = 16,
    VT_PAYLOAD = 18
  };
  uint64_t seconds_since_epoch() const {
    return GetField<uint64_t>(VT_SECONDS_SINCE_EPOCH, 0);
  }
  const flatbuffers::String *sender() const {
    return GetPointer<const flatbuffers::String *>(VT_SENDER);
  }
  const flatbuffers::String *recipient() const {
    return GetPointer<const flatbuffers::String *>(VT_RECIPIENT);
  }
  const flatbuffers::String *type() const {
    return GetPointer<const flatbuffers::String *>(VT_TYPE);
  }
  compression cmp() const {
    return static_cast<compression>(GetField<int8_t>(VT_CMP, 0));
  }
  const sequence *seq() const {
    return GetPointer<const sequence *>(VT_SEQ);
  }
  const group *grp() const {
    return GetPointer<const group *>(VT_GRP);
  }
  const flatbuffers::Vector<uint8_t> *payload() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_PAYLOAD);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<uint64_t>(verifier, VT_SECONDS_SINCE_EPOCH) &&
           VerifyOffset(verifier, VT_SENDER) &&
           verifier.VerifyString(sender()) &&
           VerifyOffset(verifier, VT_RECIPIENT) &&
           verifier.VerifyString(recipient()) &&
           VerifyOffset(verifier, VT_TYPE) &&
           verifier.VerifyString(type()) &&
           VerifyField<int8_t>(verifier, VT_CMP) &&
           VerifyOffset(verifier, VT_SEQ) &&
           verifier.VerifyTable(seq()) &&
           VerifyOffset(verifier, VT_GRP) &&
           verifier.VerifyTable(grp()) &&
           VerifyOffset(verifier, VT_PAYLOAD) &&
           verifier.VerifyVector(payload()) &&
           verifier.EndTable();
  }
};

struct parcelBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_seconds_since_epoch(uint64_t seconds_since_epoch) {
    fbb_.AddElement<uint64_t>(parcel::VT_SECONDS_SINCE_EPOCH, seconds_since_epoch, 0);
  }
  void add_sender(flatbuffers::Offset<flatbuffers::String> sender) {
    fbb_.AddOffset(parcel::VT_SENDER, sender);
  }
  void add_recipient(flatbuffers::Offset<flatbuffers::String> recipient) {
    fbb_.AddOffset(parcel::VT_RECIPIENT, recipient);
  }
  void add_type(flatbuffers::Offset<flatbuffers::String> type) {
    fbb_.AddOffset(parcel::VT_TYPE, type);
  }
  void add_cmp(compression cmp) {
    fbb_.AddElement<int8_t>(parcel::VT_CMP, static_cast<int8_t>(cmp), 0);
  }
  void add_seq(flatbuffers::Offset<sequence> seq) {
    fbb_.AddOffset(parcel::VT_SEQ, seq);
  }
  void add_grp(flatbuffers::Offset<group> grp) {
    fbb_.AddOffset(parcel::VT_GRP, grp);
  }
  void add_payload(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> payload) {
    fbb_.AddOffset(parcel::VT_PAYLOAD, payload);
  }
  explicit parcelBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  parcelBuilder &operator=(const parcelBuilder &);
  flatbuffers::Offset<parcel> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<parcel>(end);
    return o;
  }
};

inline flatbuffers::Offset<parcel> Createparcel(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t seconds_since_epoch = 0,
    flatbuffers::Offset<flatbuffers::String> sender = 0,
    flatbuffers::Offset<flatbuffers::String> recipient = 0,
    flatbuffers::Offset<flatbuffers::String> type = 0,
    compression cmp = compression_NONE,
    flatbuffers::Offset<sequence> seq = 0,
    flatbuffers::Offset<group> grp = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> payload = 0) {
  parcelBuilder builder_(_fbb);
  builder_.add_seconds_since_epoch(seconds_since_epoch);
  builder_.add_payload(payload);
  builder_.add_grp(grp);
  builder_.add_seq(seq);
  builder_.add_type(type);
  builder_.add_recipient(recipient);
  builder_.add_sender(sender);
  builder_.add_cmp(cmp);
  return builder_.Finish();
}

inline flatbuffers::Offset<parcel> CreateparcelDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    uint64_t seconds_since_epoch = 0,
    const char *sender = nullptr,
    const char *recipient = nullptr,
    const char *type = nullptr,
    compression cmp = compression_NONE,
    flatbuffers::Offset<sequence> seq = 0,
    flatbuffers::Offset<group> grp = 0,
    const std::vector<uint8_t> *payload = nullptr) {
  auto sender__ = sender ? _fbb.CreateString(sender) : 0;
  auto recipient__ = recipient ? _fbb.CreateString(recipient) : 0;
  auto type__ = type ? _fbb.CreateString(type) : 0;
  auto payload__ = payload ? _fbb.CreateVector<uint8_t>(*payload) : 0;
  return yella::fb::Createparcel(
      _fbb,
      seconds_since_epoch,
      sender__,
      recipient__,
      type__,
      cmp,
      seq,
      grp,
      payload__);
}

inline const yella::fb::parcel *Getparcel(const void *buf) {
  return flatbuffers::GetRoot<yella::fb::parcel>(buf);
}

inline const yella::fb::parcel *GetSizePrefixedparcel(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<yella::fb::parcel>(buf);
}

inline bool VerifyparcelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<yella::fb::parcel>(nullptr);
}

inline bool VerifySizePrefixedparcelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<yella::fb::parcel>(nullptr);
}

inline void FinishparcelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<yella::fb::parcel> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedparcelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<yella::fb::parcel> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace fb
}  // namespace yella

#endif  // FLATBUFFERS_GENERATED_PARCEL_YELLA_FB_H_
